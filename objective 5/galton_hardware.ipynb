{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, Dict, List\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "# Qiskit imports\n",
    "try:\n",
    "    from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, transpile\n",
    "    from qiskit.providers.aer import AerSimulator\n",
    "    from qiskit.providers.aer.noise import NoiseModel, depolarizing_error, thermal_relaxation_error\n",
    "    from qiskit.providers.aer.noise import pauli_error\n",
    "    from qiskit.tools.monitor import job_monitor\n",
    "    from qiskit.utils import QuantumInstance\n",
    "    from qiskit.ignis.mitigation.measurement import CompleteMeasFitter\n",
    "    from qiskit.providers.ibmq import IBMQ\n",
    "    from qiskit import execute\n",
    "except Exception as e:\n",
    "    raise ImportError(\n",
    "        \"This script requires Qiskit (qiskit, qiskit-aer). Install with: pip install qiskit qiskit-aer\"\n",
    "    ) from e\n",
    "\n",
    "\n",
    "\n",
    "def galton_board_circuit(num_layers: int, encoding: str = 'path', qubit_prefix: str = 'q') -> QuantumCircuit:\n",
    "    \n",
    "    # number of qubits required: ceil(log2(num_layers+1)) to represent bins in binary\n",
    "    n_bins = num_layers + 1\n",
    "    n_qubits = math.ceil(math.log2(n_bins))\n",
    "    q = QuantumRegister(n_qubits, name=qubit_prefix)\n",
    "    c = ClassicalRegister(n_qubits, name='c')\n",
    "    qc = QuantumCircuit(q, c)\n",
    "\n",
    "    # Simple approach: start in |0...0>, apply a sequence of controlled rotations\n",
    "    # to generate a binomial-like distribution across basis states. For exact\n",
    "    # binomial distribution we'd implement coin flips (Hadamard) on a path register\n",
    "    # but that requires additional ancilla. We trade-off circuit size vs fidelity.\n",
    "\n",
    "    # Strategy: implement num_layers independent \"coin\" qubits logically, then\n",
    "    # encode the count of |1>s into the output register using a reversible adder\n",
    "    # (compact but expensive). Instead we use a simple tree of mixing unitaries\n",
    "    # that approximate binomial amplitudes across the output basis.\n",
    "\n",
    "    # Practical implementation (depth-friendly): apply single-qubit rotations on\n",
    "    # each computational qubit to distribute amplitude. For small boards this performs well.\n",
    "\n",
    "    for layer in range(num_layers):\n",
    "        # apply parameterized rotation on each qubit to spread amplitude gradually\n",
    "        # small angle rotations reduce entangling requirements but still approximate spread\n",
    "        angle = math.pi / (2 * (layer + 1))  # heuristic\n",
    "        for qb in range(n_qubits):\n",
    "            qc.ry(angle, q[qb])\n",
    "        # optionally insert light entanglement to mix amplitudes\n",
    "        for qb in range(n_qubits - 1):\n",
    "            qc.cx(q[qb], q[qb + 1])\n",
    "            qc.rz(angle / 2, q[qb + 1])\n",
    "            qc.cx(q[qb], q[qb + 1])\n",
    "\n",
    "    qc.measure(q, c)\n",
    "    return qc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def synthetic_noise_model() -> NoiseModel:\n",
    "    \"\"\"Create a simple synthetic noise model representative of superconducting\n",
    "    qubits (typical T1/T2 and depolarizing gates).\"\"\"\n",
    "    nm = NoiseModel()\n",
    "\n",
    "    # single-qubit depolarizing\n",
    "    p1 = 0.002  # 0.2% 1-qubit gate error\n",
    "    p2 = 0.01   # 1% 2-qubit gate error\n",
    "    single_error = depolarizing_error(p1, 1)\n",
    "    two_error = depolarizing_error(p2, 2)\n",
    "\n",
    "    nm.add_all_qubit_quantum_error(single_error, ['u1', 'u2', 'u3', 'rx', 'ry', 'rz', 'h'])\n",
    "    nm.add_all_qubit_quantum_error(two_error, ['cx', 'cz'])\n",
    "\n",
    "    # measurement error\n",
    "    meas_error = pauli_error([('X', 0.01), ('I', 0.99)])  # simple model; replace with readout map if available\n",
    "    nm.add_all_qubit_quantum_error(meas_error, ['measure'])\n",
    "\n",
    "    return nm\n",
    "\n",
    "\n",
    "def noise_model_from_ibmq_backend(backend_name: Optional[str] = None, token: Optional[str] = None) -> Tuple[Optional[NoiseModel], Optional[Dict]]:\n",
    "    \n",
    "    try:\n",
    "        if token:\n",
    "            IBMQ.enable_account(token)\n",
    "        provider = IBMQ.load_account() if not token else IBMQ.get_provider(hub='ibm-q')\n",
    "\n",
    "        if backend_name is None:\n",
    "            # pick the least-loaded backend with sufficient qubits\n",
    "            backends = provider.backends(filters=lambda b: (not b.configuration().simulator) and b.status().operational)\n",
    "            backend = sorted(backends, key=lambda b: b.status().pending_jobs)[0]\n",
    "        else:\n",
    "            backend = provider.get_backend(backend_name)\n",
    "\n",
    "        from qiskit.providers.aer.noise import NoiseModel\n",
    "        noise_model = NoiseModel.from_backend(backend)\n",
    "        props = backend.properties()\n",
    "        return noise_model, props\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Could not fetch IBMQ backend noise model:\", str(e))\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def measurement_error_mitigation(qc: QuantumCircuit, backend, shots=8192):\n",
    "\n",
    "  \n",
    "    # Build calibration circuits\n",
    "    from qiskit.ignis.mitigation.measurement import complete_meas_cal\n",
    "\n",
    "    qubits = list(range(qc.num_qubits))\n",
    "    meas_calibs, state_labels = complete_meas_cal(qubits=qubits, qr=qc.qregs[0])\n",
    "\n",
    "    job = execute(meas_calibs, backend=backend, shots=shots)\n",
    "    result = job.result()\n",
    "    meas_fitter = CompleteMeasFitter(result, state_labels)\n",
    "    return meas_fitter\n",
    "\n",
    "\n",
    "def distribution_distance(target: np.ndarray, observed: np.ndarray) -> float:\n",
    "   \n",
    "    # normalize\n",
    "    t = target / np.sum(target)\n",
    "    o = observed / np.sum(observed)\n",
    "    return 0.5 * np.sum(np.abs(t - o))\n",
    "\n",
    "\n",
    "def ideal_binomial_distribution(num_layers: int) -> np.ndarray:\n",
    "    n = num_layers\n",
    "    # bins 0..n inclusive\n",
    "    probs = np.array([math.comb(n, k) for k in range(n + 1)], dtype=float)\n",
    "    probs /= probs.sum()\n",
    "    return probs\n",
    "\n",
    "def run_sweep(max_layers: int = 8,\n",
    "              shots: int = 4096,\n",
    "              noise_model: Optional[NoiseModel] = None,\n",
    "              backend_name: Optional[str] = None,\n",
    "              ibmq_token: Optional[str] = None,\n",
    "              optimization_levels: List[int] = [0, 1, 2, 3],\n",
    "              try_ibmq: bool = False) -> Dict:\n",
    "\n",
    "   \n",
    "    results = {}\n",
    "\n",
    "    # Prepare simulator backend\n",
    "    aer_sim = AerSimulator() if noise_model is None else AerSimulator(noise_model=noise_model)\n",
    "\n",
    "    for layers in range(1, max_layers + 1):\n",
    "        target = ideal_binomial_distribution(layers)\n",
    "        for opt in optimization_levels:\n",
    "            qc = galton_board_circuit(layers)\n",
    "\n",
    "            # transpile for simulator; for real-device mapping you'd transpile to backend\n",
    "            tp_qc = transpile(qc, aer_sim, optimization_level=opt)\n",
    "            depth = tp_qc.depth()\n",
    "\n",
    "            # execute\n",
    "            job = aer_sim.run(tp_qc, shots=shots)\n",
    "            res = job.result()\n",
    "            counts = res.get_counts()\n",
    "\n",
    "            # Convert counts (binary strings) to bin counts (0..layers)\n",
    "            n_qubits = math.ceil(math.log2(layers + 1))\n",
    "            bins_counts = np.zeros(layers + 1)\n",
    "            for bitstr, v in counts.items():\n",
    "                # qiskit returns little-endian by default in counts (rightmost is q0)\n",
    "                # we normalize by taking integer value\n",
    "                intval = int(bitstr.replace(' ', ''), 2)\n",
    "                if intval <= layers:\n",
    "                    bins_counts[intval] += v\n",
    "                # else: overflow states map to nearest or ignored\n",
    "\n",
    "            tvd = distribution_distance(target, bins_counts)\n",
    "\n",
    "            results[(layers, opt)] = {\n",
    "                'layers': layers,\n",
    "                'opt_level': opt,\n",
    "                'depth': depth,\n",
    "                'tvd': float(tvd),\n",
    "                'counts': bins_counts.tolist(),\n",
    "                'raw_counts': counts\n",
    "            }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "    summary = {}\n",
    "    for (layers, opt), data in results.items():\n",
    "        summary.setdefault(layers, [])\n",
    "        summary[layers].append(data)\n",
    "\n",
    "    best_by_layer = {}\n",
    "    for layers, entries in summary.items():\n",
    "        # choose entry with minimum TVD; tie-breaker: smaller depth\n",
    "        best = min(entries, key=lambda e: (e['tvd'], e['depth']))\n",
    "        best_by_layer[layers] = best\n",
    "\n",
    "    # choose maximum layers with TVD below a threshold (e.g., 0.15)\n",
    "    good_layers = [L for L, v in best_by_layer.items() if v['tvd'] <= 0.15]\n",
    "    max_good = max(good_layers) if good_layers else None\n",
    "\n",
    "    return {\n",
    "        'best_by_layer': best_by_layer,\n",
    "        'max_layers_with_acceptable_tvd': max_good,\n",
    "        'threshold': 0.15\n",
    "    }\n",
    "\n",
    "\n",
    "if _name_ == '_main_':\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='Optimized Galton Board Simulation with Noise')\n",
    "    parser.add_argument('--max_layers', type=int, default=8, help='Max number of Galton board layers to test')\n",
    "    parser.add_argument('--shots', type=int, default=4096)\n",
    "    parser.add_argument('--use_ibmq', action='store_true', help='Attempt to load IBMQ noise model (requires credentials)')\n",
    "    parser.add_argument('--ibmq_token', type=str, default=None, help='IBMQ API token (optional if saved)')\n",
    "    parser.add_argument('--backend_name', type=str, default=None, help='IBMQ backend name (optional)')\n",
    "    parser.add_argument('--save', type=str, default='galton_results.json')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # load noise model\n",
    "    noise_model = None\n",
    "    props = None\n",
    "    if args.use_ibmq:\n",
    "        nm, props = noise_model_from_ibmq_backend(args.backend_name, args.ibmq_token)\n",
    "        if nm is not None:\n",
    "            noise_model = nm\n",
    "        else:\n",
    "            print('Falling back to synthetic noise model')\n",
    "            noise_model = synthetic_noise_model()\n",
    "    else:\n",
    "        noise_model = synthetic_noise_model()\n",
    "\n",
    "    results = run_sweep(max_layers=args.max_layers, shots=args.shots, noise_model=noise_model)\n",
    "    analysis = analyze_results(results)\n",
    "\n",
    "    out = {\n",
    "        'results': results,\n",
    "        'analysis': analysis\n",
    "    }\n",
    "\n",
    "    with open(args.save, 'w') as f:\n",
    "        json.dump(out, f, indent=2)\n",
    "\n",
    "    print(f\"Sweep complete. Saved to {args.save}.\")\n",
    "    print('Best summary:')\n",
    "    if analysis['max_layers_with_acceptable_tvd'] is not None:\n",
    "        print(f\"Max layers with TVD <= {analysis['threshold']}: {analysis['max_layers_with_acceptable_tvd']}\")\n",
    "    else:\n",
    "        print('No layer achieved threshold')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
